\documentclass[11pt]{article}
\usepackage{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{gensymb}
\usepackage[affil-it]{authblk}
\usepackage[toc,page]{appendix}
\usepackage{pifont}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{draftwatermark}

\SetWatermarkText{DRAFT}
\SetWatermarkScale{6}
\SetWatermarkLightness{0.95}

% \geometry{letter} % or letter or a5paper or ... etc
% \geometry{landscape} % rotated page geometry

% See the ``Article customise'' template for come common customisations

\title{Optimizing Actuator Network Positions}
\author{Robert L. Read
  \thanks{read.robert@gmail.com}
}
\affil{Founder, Public Invention, an educational non-profit.}


\date{\today}

%%% BEGIN DOCUMENT
\begin{document}

\maketitle

%% \tableofcontents

\section{Introduction}

The Gluss Project builds robots that are networks of linear actuators connected with concentric joints.
A fundamental problem of contronlling such robots is to move one of the joints, or nodes, to a given
position.
More generally, we would like to leave some nodes (the feet) in position which we move another
set of nodes (other feet, or graspers) to some positions that we specify. In general, this may
require a motion of every actuator in the network.

Design of efficient gaits and motion depends on this abiity. The ability to crawl over obstacles
depends on this ability.

Although the current robot is a tetrahelix, a structure isomorphic to the Boerdijk--Coxeter
helix, we would eventually like to build robots and machines with general geometries,
including non-tetrahedral geometries, and will develop the algorithm with that in mind.

This problem is dependent on the physical nature of the actuator: it can change length
between and minimum and maximum length.
This problem is silimar to optimization problems such as solved by linear programming.
However, at a minimum the constraints are quadratic.


The mininum length and maximum length are defined by the Cartesian distance formula,
which expressed as a length contains a square root, but we may always work with the
square of this formula, leaving quadratic formualae.  I'm pretty sure is
is a subcase of Conic Quadratic optimization: http://docs.mosek.com/modeling-cookbook/cqo.html
because we are dealing with Euclidean norms.

Note we are dealing with positive definite matrices.


\section{Formulation}

We now define the problem ACTNETOPT.


The input to our problem can be formalized as:
\begin{itemize}
 \item An input dimension $d$ (probably 2 or 3.) Nodes positions are elemenst of $\mathbb{R}^d$
 \item A model of a net of $n$ nodes in the form of a graph $G = (N, E)$.
 \item A mapping from from node index $i$ to the square of the minimum length $Y(i)$ and maximum length $Z(i)$ It is
   convenient to treat these as the square of the length, or quadrance.
\item A set of goal points $H$ $h_j$ associated with node $j$ chosen from $\mathbb{R}^d$.
\item A linear weighting $w(j)$ of goal points interpreted as the cost of not placing the node $j$ at
  the goal point $g_j$ proportional to the square of that distance.
\item A set of static nodes $S$ which may not be moved by the algorithm.
\end{itemize}

We now attempt to formulate the problem as a QCQP.
The quadratically constrained quadratic programming problem can be formulated:
\begin{align*}
\text{minimize: }  & \frac{1}{2} x^TP_0x + q_0^Tx \\
\text{subject to: } & \frac{1}{2} x^TP_ix + q_i^Tx + r_i \leq 0
\end{align*}

In ACTNETOPT case we have no equality constraints.

In order to create this in matrix form, we create from it:
\begin{itemize}
\item A model of our robot represented by a symmetric matrix $M^{n \times n}$, where $n$ is the number of joints in the robot, and
  a $M_{i,j} = 1$ if the nodes $i$ and $j$ are connected by an acutator, and is zero if not. Elements of $M$ are real-valued.
\item Similar matrices $Y^{n \times n}$ and $Z^{n \times n}$ representing respectively the minimum and quadrance (square of the distance) for each actuator $i,j$.
  If actuator $i,j$ does not exist in the robot, then $Y_{i,j}$ and $Z_{i,j}$ are undefined. (Note that $Y_{i,j} = 0$ is an interesting case. Furthermore
  we are particularly interested in the case then all $Y$ and $M$ values are equal where they are defined.) Elements of $Y$ and $Z$ are real-valued.
\item A set of goal points $g_j$ associated with node $j$ chosen from $\mathbb{R}^d$.
\item A goal matrix $P_0^{n \times n}$ which is positive definite and represents a potentially weighted sum of the square of the Euclidean norm, or quadrance,
  of the position of nodes in our $x_i$ from their respective goal postions $g_i$.
\end{itemize}

The output of the algorithm is a vertical vector $X$ which satisifies all contraints and minimizes the objective function $f$.

To the author it was not obvious how to construct the matrices in question, so it is perhaps worth stating this explicity.
Let us consider a single upper bound constraint, $z_{i,j}$. $z_i$ is a scale, $x_i$ is a 2- or 3-vector.
\begin{align*}
  \vert \mathbf{x_i} - \mathbf{x_j} \rvert  \leq z_{i,j} \\
  (x_{i_x} - x_{j_x})^2 + (x_{i_y} - x_{j_y})^2 + (x_{{i_z}} - x_{j_z})^2  \leq z_{i,j} \\
 x_{i_x}^2 + -2x_{i_x}x_{j_x} +  x_{j_x}^2 + x_{i_y}^2 + -2x_{i_y}x_{j_y} + x_{j_y}^2 + x_{i_z}^2 + -2x_{i_z}x_{j_z}+ x_{j_z}^2  \leq z_{i,j} \\  
\end{align*}
Which can be represented in the matrix $P_i$, assume $i = 0$, $j = 2$, the 3-vectors are unpacked linearly.
\[
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 & 0 & -2 & 0 & 0  \\
  0 & 1 & 0 & 0 & 0 & 0 & 0 & -2 & 0  \\
  0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & -2  \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\
  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 
\end{pmatrix}
\]

This matrix has 9 entries representing the nine coefficients. In fact it is
positive definite (proof?).

So: $ x^TP_ix + r_i \leq 0 $ represents a distance constraint when $r_i$ is the square of
the mininum distances for actuator $i$.

The goal matrix $P_0$ can be constructed similarly, multiplying each set of 9 entries by
a $w(j)$ to weight that node.

Since there is one $P_i$ for each actuator and each such matrix has only nine entries,
this entire approach is very
sparse. In the fact the constraint matrices are so specialized that
we can expect an algorithm specific to this
problem to do well.  Since most of the quadratic constraint
programming packages are commercial, there is a strong
incentive to develop a specific algorithm.

\section{Why we may use Powell's Method}

This is fundatmentally a constraint optimization problem. However, we can model it as a continuous
optimization problem with heavy penalties for violating the constraints.

Given that we have a relatively small number of nodes, it is possible that a global optimization
system, such as Powell's Method, might work just fine for what we are trying to acheive here.

I do not anticipate the space to have many local minima. Although using Powell's method
is probably wasteful from a scientific point of view, coding it has a number of advantages:
\begin{itemize}
\item This will be a contribution to open source systems in general.
\item It can be used as a subroutine in the Strainfront algorithm below.
  \item It may simply solve our problem without much additional effort.
\end{itemize}

Powell's method has been implemented many times in C and C++. However, I am contemplating
implemeting it in JavaScript.  This could be considered a forward-thinking action in the vanguard,
or it could be considered a limitation.  Since Public Invention leans very heavily on browser-based
functionality to be as accessbile to as many people as possible, a JavaScript implemention is
potentially useful because it can be run in the  browser.

Certainly at present my immediate goals are to be able to work on the Ammo simulation which
is all browser-based.  From our emacs-lisp control structure, we can call a C function
or a Node function with inter-process communication equally easily.

If I can't do this in JavaScript, it will be inaccessible to all of my other browser-based
code.

\section{Open source project: fmin}

There is an open source javascript project called fmin that looks really awesome and appears to
be what we want.  The only limitation is that it requires the computation of the gradient at
each point.  I wanted to avoid this, but in fact it is quite calculatable for this situation,
so I think the best thing is for me to actually work out the gradient and use these methods,
which is undoubtably a better approach than relying purely on a non-gradient approach.

So here begins my attemtp to define the objective function in a differentiable way.

\begin{equation}
  f(\mathbf{x}) = r(\mathbf{x}) + p(\mathbf{x});
\end{equation}

\begin{equation}
  r(\mathbf{x}) = \sum_{i \in H} w_id(\mathbf{x}_i,Targ_i)^2 
\end{equation}

\begin{equation}
  r(\mathbf{x}) = \sum_{i \in H} w_i\big((x_{ix} - h_{ix})^2 + (x_{iy} - h_{iy})^2 + (x_{iz} - h_{iz})^2\big)
\end{equation}

where $\mathbf{x}$ represents the vector of 3-dimensional node positions, $p(\mathbf{x})$
represents a penalty function defined by:
\begin{equation}
  p(\mathbf{x}) = \sum_{e_{i,j} \in E} max(0, (y(i,j) - \lVert \mathbf{x}_i - \mathbf{x}_j \rVert^2  ))
  + max(0,  (\lVert \mathbf{x}_i - \mathbf{x}_j \rVert^2 - z(i,j) ))
\end{equation}


\begin{multline}
  p(\mathbf{x}) = \sum_{e_{i,j} \in E} max \bigg(0, \Big(y(i,j) - ((X_{ix} - X_{jx})^2 + (X_{iy} - X_{jy})^2)  \Big) \bigg) \\
  + max \bigg(0,  \Big((X_{ix} - X_{jx})^2 + (X_{iy} - X_{jy})^2) - z(i,j) \Big) \bigg)
\end{multline}

To use the fmin software, we need to compute the derivative of $f$. In parcticular
it requires the computation of the partial derivative for each variable $x_i$.
\begin{equation}
  f'(\mathbf{x}) = r'(\mathbf{x}) + p'(\mathbf{x})
\end{equation}

\begin{equation}
  \frac{\partial r}{\partial x_i}  =  2w_i(x_i - h_i)
\end{equation}

\begin{multline}
  \frac{\partial p}{\partial x_i}
  =  \sum_{j:e_(i,j) \in E}
  -2((x_{ix} - x_{jx}) + (x_{iy} - x_{jy}) + (x_{iz} - x_{jz}))\big[\lVert \mathbf{x}_i - \mathbf{x}_j \rVert < y(i,j)\big]\\
  + 2((x_{ix} - x_{jx}) + (x_{iy} - x_{jy}) + (x_{iz} - x_{jz}))\big[\lVert \mathbf{x}_i - \mathbf{x}_j \rVert > z(i,j)\big]
\end{multline}

\begin{multline}
  \frac{\partial p}{\partial x_i}
  =  \sum_{j:e_(i,j) \in E}
  \big((x_{ix} - x_{jx}) + (x_{iy} - x_{jy}) + (x_{iz} - x_{jz})\big) \big(-2\big[\lVert \mathbf{x}_i - \mathbf{x}_j \rVert < y(i,j)\big]
  + 2\big[\lVert \mathbf{x}_i - \mathbf{x}_j \rVert > z(i,j)\big]\big)
\end{multline}

where the square brackets represent Iverson notation, which evalutes to $1$ if the condition
inside the brackets is true and $0$ if false.

It seems likely that we can compute the derivatives of these functions in code relatively easily.
My plan is to complete that and then try to work this into the existing actoptmin framework.

We must decide whether to treat the x,y,z coordinates as a vector or as independent variables in
this system. I believe mathematically, it is 100\% possible to treat them as independent variables.

\section{First Algorithm}

Although this problem is a quadratic constraint problem,
is is highly specialized, and such solvers are not
freely available. Because our robots are at present models
(the current robot has 24 actuators), it is
reasonable to assume this nut can be cracked with a small hammer.

Basic ideas for an algorithm:
\begin{itemize}
\item Keep a set of goals, which are nodes to move.  Attempt to compute a ``goodness''
  for each goal,
  which will basically be the improvement of the weighted score if the goal is reached. If the
  expected change is equal (which can happen?) then order by shortest move.
\item Keep a set of goals and search Breadth-first. For a given goal, move the shortest distance
  of all limitations applied to it.  Amoungst goals, move the distance that increases the goodness
  the most.
\item If in processing a goal new new goals are added possibly
  take only the highest ``goodness'' goal in order
  to keep the set of goals as small as possible.
  \item Keep moving so long as each move improves the score by an input $\epsilon$.
\end{itemize}

So we can try imagine the data structures used by the algotihm:

A priority Queue ordered first by Breadth from the primary goals and secondly by goodness.
A goal is a node, a position, and an estimated change to the weighted score
if the goal is acheived.
A goal additionally has back pointers to the nodes that may improve
if the node of this goal is improved.

The basic operation is:
Take the goal from the top of the priority queue.
Try to move the node to the goal.

If the node moves but does not reach its goal, backtrack to the nodes that are expected
to improve. Move each node in the goal queue as possible as you back track.

If the node cannot be moved, find the connected nodes
which are not in the fixed set. Compute a goal point for each of these nodes. Compute the
expected change to the weighting if these points are are acheived. If that expected
goodness is greater than epsion, add the goal to the
priority queue.

What are the termination properties of this algorithm?
Invariant: Every move improves the goodness.

Conjecture: The estimate of the improvement of goodness is guaranteed to improve the
goodness that much.

Even if it has to visit all N nodes, the running time of O( (inital score / epsilon ) * N )

\section{Strainfront Algorithm}

The idea here is to perturb the target node, creating a \emph{strainfront}. A strainfront is a
set of directed edges. The strainfront tries to relieve strain by moving the head node of the
edge. Each such move may cause new edges to be added to the strainfront. When a strainfront
reaches a fixed nodes, it is reflected backwards.

This seems like a really beautiful idea to me.

Questions remain:
\begin{itemize}
\item in what order to we process the strainfront?
\item how do we prove termination?
\item can we prove that all strain is relieved by this algorithm? (yes, because
  it can leave things unchanged and it starts with a legal configuration.)
\end{itemize}

Here is my attempt to start the algorithm

Input: A node to move $a$, and target point to move it to, $\vec{v}$.
A connectivity graph $G$, and a set of fixed nodes $F$, and
a legal configuration $C$ satisfying all constraints.

Output: A new legal configuration with $a$ as close to $\vec{v}$ as possible.

Begin Algorithm STRAINFRONT:

Let S = perturb($a,\vec{v}$).

While $S \neq \emptyset$ do:

$ S = Relieve(S) $

End Algorithm


Subroutine PERTURB($a,\vec{v}$):
Input $a$, a node, and $\vec{v}$, a desired position for $a$.
Create empty strainfront $S$.

If $a$ is not marked ``PERTURBED'', Move $a$ to $G$.
Mark $a$ ``PERTURBED'' and annonate it with the original position.

For each node $b_i$ connected  to $a$ in $G$,
compute $s = strain(a,b_i)$. Strain is negative if they are too far apart,
positive if they are too close together.
If $s \neq 0$, add  $a \rightarrow b_i$ to the strainfront $S$. Return $S$.

Subroutine RELIEVE(S,C) (where S is a strainfront):

Outpout: a new strainfront and configuraiton

Choose and remove a directed edge $x \rightarrow y$ from the strainfront in order
of number of edges from our start node $a$.

If $y$ is a fixed node or marked ``FIXED'' node, add $y \rightarrow x$ to the strainfront and return.

Mark the node $y$ ``FIXED''.

Let $z_s = \text{LEAST-STRAIN}(y,S,C)$.

Return $Perturb(S,x,z_s)$.

Subroutine $\text{LEAST-STRAIN}(x,y,S,C)$:

There are a variety of possible implemetations for this.  We can evolve it
rather simply I think.

If $y$ is ``PERTURBED'', then we will only seek solutions that occur on a straight line
between the current $y$ position and the original $y$ position.

First algorithm: for the $N$ neighbors of $y$, compute the at most $4N^2$ intersection points
of the circles corresponding to the lower bound and upper bound of each circle. Test
each such intersection point for being part of the ``free region'' (that is, satisfying all
constraints.)  Return the free region intersection point that minimizes the strain on the
$x \rightarrow y$ joint.

If $y$ is PERTURBED, insure that all neighbor constraints are satisfied, by restoring
to the original position if necessary.



Sketch of termination:
Each node is visited at most twice.

Sketch of correctness:
The algorithm proceeds as two wave fronts: a wave front generated by the first perturbation,
and a wavefront reflected off the fixed nodes going in the opposite direction. The
internal configurations temporarily violate the constraints.  However, once the back
wave has passed a node, it has all constraints obeyed, if nessary by restoration to its
original position.

\section{Notes}

This algorithm is almost certainly not globally optimal.  I have not even proved correctness
nor termination.

However, it seems pretty clearly that one operation of the algorithm is extraordinarily fast.

If we kept a data structure that kept intersection points, it is possible that we would
have an $O(n)$ algorithm, where $n$ is the number of nodes, but we may very well have
less than that if the net has slack to acheive the position in question.

It seems that this may be a very valuable adjunct algorithm to the algorithms that
use a general purpose objective function, which could also be used.

An open question remains how the algorithm will function with repeated uses.
For example, will it fine tune a solution?  Possible not, due to the way the
intersection points are used.

Note that the algorithm can be improved by lambda-lifting selection critera into
the basic strain-front algorithm. This could allow better control of the  works;
for example, on a secon iteration, an algorithm that departed from the basic
intersection point system could be valuable.

The current algorithm may be adding too much to the strain front.

Major TODOs at this point are:
\begin{itemize}
\item clean up the code!
\item work out termination proof and asymptotic complexity.
\item count major operation.
\item shift to squares instead of square roots whenever possible.
\item lambda lift
\item MAKE WORK WITH 3D vectors!
\item develop more awesome test cases.
  \item develop a highly over constrained network.
  \item develop interactive work.
  \end{itemize}

\section{A Key Idea}

The problem should be recursively reducible. For example, A triangle can
be reducde to a linear segment with an apex at one end and the midpoint of the
other side at the other end.  In principle, this allows a 3-fold reduction
in the complexity of the problem.  It also may lead to more symmetric solutions,
even based on the intersection-point only algorithm.  In small examples this seems
to work.



\section{References}



\end{document}


https://people.eecs.berkeley.edu/~elghaoui/Teaching/EE227A/lecture6.pdf

http://homes.cs.washington.edu/~sagarwal/aat.pdf

http://zoonek.free.fr/blosxom/R/2012-06-01_Optimization.html

http://docs.mosek.com/modeling-cookbook/cqo.html
